---
layout: single
title: "Intro to GANs"
twitter-image: /assets/posts/gan/gan_card.png
excerpt: "GANs are a type of generative models that try to learn the underlying distribution of a given dataset by making two sub-models compete against each other in a zero sum game."
header:
  teaser: /assets/posts/gan/gan_card.png
  overlay_image: /assets/posts/gan/gan_header.png
  overlay_filter: 0.5 # rgba(255, 0, 0, 0.5), linear-gradient(rgba(255, 0, 0, 0.5), rgba(0, 255, 255, 0.5))

date:   2021-06-01 20:30:00 +0530
last_modified_at: 2021-06-20 20:30:00 +0530
categories: ML GAN
published: true

# table
toc: true
# toc_label: "Label goes here"
# toc_icon: "<some font awesome icon>"
toc_sticky: true

# sidebar
sidebar:
  - title: "Generative Adversarial Networks"
  - image: /assets/images/ml/gan-sidebar.png
    image_alt: "Images generated by GANs"

  - title: All posts
  - nav: ml-posts

  - title: See also
  - nav: other-posts

mode-collapse:
  - url: /assets/posts/gan/mode-collapse-1.png
    image_path: /assets/posts/gan/mode-collapse-1.png
    alt: "example image 1"
    title: "Discriminator successfully catching all digits except 1 and 7"
  - url: /assets/posts/gan/mode-collapse-2.png
    image_path: /assets/posts/gan/mode-collapse-2.png
    alt: "example image 2"
    title: "Generator learning to create only 1 and 7 to fool the discriminator"
---
# Intro

GANs are generative models that try to learn the underlying distribution of a given dataset by making two sub-models compete against each other in a zero-sum game. For example, we might give the model a large number of images of human faces and then the GAN should hopefully learn to generate new realistic images of people that aren't in the dataset. The two sub-models are called the generator and the discriminator.

The generator is the thing that does the generative modeling and tries to create new points that plausibly come from the same dataset. The discriminator tries to discriminate whether a particular image came from the real dataset or the generator.


# Loss function

Since there are two different models in GANs that work against each other, we need two loss functions to train them, one for each.

For the discriminator, we want it to correctly classify the generated images being real or fake, so we want to penalize incorrect predictions. We can use a simple binary cross entropy or BCE loss for this. In a batch of size N, if the correct label for the ith image is $ y_i $ and the value predicted by the discriminator is $ \hat{y_i} $, then the loss becomes:

$$ L_{D}(Y, \hat{Y}) = -\frac{1}{N} \sum_{i=1}^{N} y_i \cdot log(\hat{y_i}) + (1-y_i) \cdot log(1-\hat{y_i}) $$

For the generator, we want the opposite, because we want the discriminator to incorrectly predict our generated images as real. We give the discriminator a set of generated images and penalize the generator for images that the discriminator correctly predicts as being fake. So in this case, the true labels ($ y_i $) are 0 for all the examples and we want the predictions to be as close to 1 as possible, thus the loss function for the generator becomes:

$$ L_{G}(\hat{Y}) = -\frac{1}{N} \sum_{i=1}^{N} log(\hat{y_i}) $$

**Note:** While implementing the generator loss yourself make sure you don’t update the weights of the discriminator during this step.


# Training GANs

The training of a GAN involves two steps, which are alternated during the training process.



1. The discriminator trains on images generated by the generator mixed with real images from the dataset
2. The generator is trained based on the predictions given by the discriminator on the generated images.

In the beginning, neither the generator nor the discriminator knows what they are doing. The generator generates really bad images that look nothing like the dataset because it has no information about what the images should look like. As the discriminator slowly learns how to differentiate between real and fake images, it propagates that information to the generator in the form of generator loss that is based on how realistic each image looks to the discriminator. As the training process goes on, both the generator and the discriminator get better until eventually, the generator starts generating images that look real even to humans.

While the basic idea behind GANs is simple and intuitive, in practice many potential factors can lead to poor performance or unexpected results. Some of these issues are listed below -


## Vanishing gradients

During training, the job of the discriminator is much easier compared to the generator. While the discriminator only has to correctly predict which image is real and which one is fake, the generator has to create a realistic image using just the noise vector as input. Because of this reason, the discriminator might learn much faster than the generator and start to correctly predict all the generated images as fakes. With traditional activation functions like sigmoid or tanh, the gradients become very small when the discriminator predicts ‘real’ or ‘fake’ with very high confidence. When that happens, the generator will not get any meaningful feedback to update its weights and improve, further exacerbating the problem making the generator stuck in a non-optimal place.

Some solutions proposed to deal with this issue include using [Wasserstein loss](https://arxiv.org/abs/1701.07875) or a modified minimax loss proposed in the [original GAN paper](https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf).


## Failure to converge

If you are familiar with reinforcement learning you might have seen another issue that might arise in this process. Both the generator and the discriminator are chasing non-stationary targets, which means that they might fail to converge. Take a simple image classification problem, for example, there, the dataset is static, i.e., it does not change during the training process, and so the optimal weights that we are trying to reach are constant and we can use gradient descent to slowly reach that point. In a GAN, however, once the generator is updated, the images it will produce in the next step for the discriminator will be different, and so the target towards which the discriminator is trying to move is itself moving. Similarly, for the generator, as the discriminator gets better, the loss for the same generated image will keep changing.

Because of this, GANs frequently fail to converge. As mentioned in this [google developers post](https://developers.google.com/machine-learning/gan/problems), some regularization methods like [adding noise to discriminator inputs](https://arxiv.org/pdf/1701.04862.pdf) and [penalizing discriminator weights](https://arxiv.org/pdf/1705.09367.pdf) can be used to improve GAN convergence. 


## Mode collapse

Often the distribution of data that we are trying to capture with our GAN is multimodal, i.e., with more than one mode or peak in the distribution. For example, in the MNIST dataset, there are 10 classes (digits 0 to 9) and each of those corresponds to a mode in the distribution of that dataset, with the spread around those modes denoting the variation that can be found within each class.

{% include gallery id="mode-collapse" caption="Example of mode collapse while trying to generate hand written digits. Source: [Build Basic Generative Adversarial Networks (GANs) \| Coursera](https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans)" %}

During training, the discriminator might find it easier to distinguish between real and fakes of one class compared to others. Consequently, the generator might stop generating images of that class because it is easier to fool the discriminator in other classes. After a few steps like this, you might find that the generator is only generating images from one of the classes (the digit ‘1’ for example). This is called mode collapse.

You can deal with this issue using [Wasserstein Loss](https://arxiv.org/abs/1701.07875) or [Unrolled GANs](https://arxiv.org/abs/1611.02163).


# References



1. [Build Basic Generative Adversarial Networks (GANs) \| Coursera](https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans)

2. [GAN Training  \|  Generative Adversarial Networks  \|  Google Developers](https://developers.google.com/machine-learning/gan/training)

3. [Common Problems  \|  Generative Adversarial Networks  \|  Google Developers](https://developers.google.com/machine-learning/gan/problems)

4. [[1406.2661] Generative Adversarial Networks (arxiv.org)](https://arxiv.org/abs/1406.2661)